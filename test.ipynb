{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import wfdb\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa895aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. ECG Dataset Loader\n",
    "# ===============================\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "033bb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 2. Preprocessing\n",
    "# ===============================\n",
    "def bandpass_filter(signal, lowcut=0.5, highcut=40, fs=360, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut/nyquist, highcut/nyquist], btype=\"band\")\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def load_mitbih(path=\"./mit-bih-arrhythmia-database-1.0.0/\", record_list=None, segment_length=1000):\n",
    "    \"\"\"\n",
    "    Loads MIT-BIH dataset and prepares it for testing.\n",
    "    - path: dataset folder\n",
    "    - record_list: which records to use (e.g. [\"100\", \"101\"])\n",
    "    - segment_length: fixed length for CNN input\n",
    "    \"\"\"\n",
    "    if record_list is None:\n",
    "        record_list = [\"100\", \"101\", \"103\", \"105\"]  # you can expand\n",
    "\n",
    "    X, y = [], []\n",
    "    for rec in record_list:\n",
    "        record = wfdb.rdrecord(path + rec)\n",
    "        ann = wfdb.rdann(path + rec, \"atr\")\n",
    "\n",
    "        signal = record.p_signal[:,0]  # use lead 0\n",
    "        signal = bandpass_filter(signal, fs=record.fs)\n",
    "\n",
    "        # Slice into segments aligned with annotations\n",
    "        for i, sample in enumerate(ann.sample):\n",
    "            start = max(0, sample - segment_length//2)\n",
    "            end = start + segment_length\n",
    "            if end > len(signal):\n",
    "                continue\n",
    "            segment = signal[start:end]\n",
    "            if len(segment) == segment_length:\n",
    "                X.append(segment)\n",
    "                # Convert annotation symbol to binary label (Normal vs Abnormal)\n",
    "                label = 0 if ann.symbol[i] == \"N\" else 1\n",
    "                y.append(label)\n",
    "\n",
    "    X = np.expand_dims(np.array(X), 1)  # (N, 1, segment_length)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f7607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. ResNet Model (same as training)\n",
    "# ===============================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=7, stride=stride, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2, n_leads=1):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(n_leads, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1]*(blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "def ResNet18_1D(num_classes=2, n_leads=1):\n",
    "    return ResNet1D(ResidualBlock, [2,2,2,2], num_classes=num_classes, n_leads=n_leads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d8e9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.31      0.33      0.32      1083\n",
      "  Arrhythmia       0.96      0.95      0.95     16245\n",
      "\n",
      "    accuracy                           0.91     17328\n",
      "   macro avg       0.63      0.64      0.64     17328\n",
      "weighted avg       0.91      0.91      0.91     17328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import wfdb\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os\n",
    "\n",
    "# ===============================\n",
    "# 1. ECG Dataset Loader\n",
    "# ===============================\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ===============================\n",
    "# 2. Preprocessing\n",
    "# ===============================\n",
    "def bandpass_filter(signal, lowcut=0.5, highcut=40, fs=360, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut/nyquist, highcut/nyquist], btype=\"band\")\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def load_mitbih(path, segment_length=1800):\n",
    "    \"\"\"\n",
    "    Load MIT-BIH arrhythmia dataset.\n",
    "    - path: path to dataset directory\n",
    "    - segment_length: number of samples per segment (default 5s at 360 Hz)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    records = [f[:-4] for f in os.listdir(path) if f.endswith(\".dat\")]\n",
    "\n",
    "    for rec in records:\n",
    "        sig, fields = wfdb.rdsamp(os.path.join(path, rec))\n",
    "        ann = wfdb.rdann(os.path.join(path, rec), \"atr\")\n",
    "\n",
    "        # use lead 0\n",
    "        lead = sig[:,0]\n",
    "        lead = bandpass_filter(lead, fs=fields[\"fs\"])\n",
    "\n",
    "        # segment signal\n",
    "        n_segments = len(lead) // segment_length\n",
    "        for i in range(n_segments):\n",
    "            segment = lead[i*segment_length:(i+1)*segment_length]\n",
    "            if len(segment) == segment_length:\n",
    "                # duplicate into 12 channels\n",
    "                segment = np.tile(segment, (12,1))  # shape = (12, L)\n",
    "                X.append(segment)\n",
    "                y.append(1 if any(l in ann.symbol for l in [\"V\",\"A\",\"L\",\"R\"]) else 0)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# ===============================\n",
    "# 3. ResNet Blocks and Model\n",
    "# ===============================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=7, stride=stride, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2, n_leads=12):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(n_leads, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1]*(blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return self.fc(out)\n",
    "\n",
    "def ResNet18_1D(num_classes=2, n_leads=12):\n",
    "    return ResNet1D(ResidualBlock, [2,2,2,2], num_classes=num_classes, n_leads=n_leads)\n",
    "\n",
    "# ===============================\n",
    "# 4. Main Testing\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"mit-bih-arrhythmia-database-1.0.0/\" \n",
    "    X, y = load_mitbih(path)\n",
    "\n",
    "    # Dataset\n",
    "    test_ds = ECGDataset(X, y)\n",
    "    test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "    # Load model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = ResNet18_1D(num_classes=2, n_leads=12)\n",
    "    model.load_state_dict(torch.load(\"ptb-xl/models/second.pth\", map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation\n",
    "    preds, probs, targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            out = model(Xb)\n",
    "            prob = F.softmax(out, dim=1)[:,1].cpu().numpy()\n",
    "            pred = torch.argmax(out, dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            probs.extend(prob)\n",
    "            targets.extend(yb.cpu().numpy())\n",
    "\n",
    "print(classification_report(targets, preds, target_names=[\"Normal\", \"Arrhythmia\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0bbec",
   "metadata": {},
   "source": [
    "# **1dcnn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2201437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "950ba544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 1. Load Your Model\n",
    "# ======================\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, padding=3),  # 12-lead input\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)  # makes it [batch, 128, 1]\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(128, num_classes)  # matches checkpoint\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten [batch, 128, 1] -> [batch, 128]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# -------------------\n",
    "# Load trained model\n",
    "# -------------------\n",
    "model = CNN1D(num_classes=2)\n",
    "state_dict = torch.load(\"ptb-xl/models/first.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbd0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 2. MIT-BIH Dataset Loader\n",
    "# ======================\n",
    "class MITBIHDataset(Dataset):\n",
    "    def __init__(self, data_dir, record_list, window_size=500):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.window_size = window_size\n",
    "\n",
    "        for record in record_list:\n",
    "            record_path = os.path.join(data_dir, record)\n",
    "            sig, fields = wfdb.rdsamp(record_path)\n",
    "            ann = wfdb.rdann(record_path, 'atr')\n",
    "\n",
    "            sig = sig[:, 0]  # use lead MLII\n",
    "            sig = (sig - np.mean(sig)) / np.std(sig)\n",
    "\n",
    "            for idx, sym in zip(ann.sample, ann.symbol):\n",
    "                if sym in ['N', 'L', 'R']:  # Normal beats\n",
    "                    label = 0\n",
    "                elif sym in ['V', 'A']:     # Arrhythmia\n",
    "                    label = 1\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                start = max(0, idx - window_size // 2)\n",
    "                end = start + window_size\n",
    "                if end <= len(sig):\n",
    "                    beat = sig[start:end]\n",
    "                    self.samples.append(beat)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        self.samples = np.array(self.samples)\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.samples[idx]\n",
    "        y = self.labels[idx]\n",
    "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)  # (1, L)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2696b936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      0.11      0.20      4196\n",
      "  Arrhythmia       0.01      0.78      0.02        41\n",
      "\n",
      "    accuracy                           0.11      4237\n",
      "   macro avg       0.49      0.44      0.11      4237\n",
      "weighted avg       0.97      0.11      0.19      4237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# 3. Run Testing\n",
    "# ======================\n",
    "data_dir = \"mit-bih-arrhythmia-database-1.0.0\"\n",
    "records = [\"100\", \"101\", \"102\"]  # pick a few records\n",
    "dataset = MITBIHDataset(data_dir, records)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dataloader:\n",
    "        # x shape: [batch, 1, length]\n",
    "        x = x.repeat(1, 12, 1)   # expand single-lead -> 12 leads\n",
    "        outputs = model(x)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        y_true.extend(y.numpy())\n",
    "        y_pred.extend(preds.numpy())\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Arrhythmia\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
